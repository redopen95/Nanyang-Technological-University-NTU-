{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from pyswarm import pso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Function that prints all required data of a graph G.\n",
    "(Plots network graph and vertex degree distribution histogram, then prints |V|,|E|, \n",
    "average vertex degree, CC, number of triangles, average path length and diameter.)'''\n",
    "def print_network_data(G):\n",
    "    v_degrees = np.array(list(dict(nx.degree(G)).values()))\n",
    "    nx.draw(G, node_size = 2.5 * v_degrees, node_color = 'blue',\n",
    "    alpha = 0.2, edge_color = 'green')\n",
    "    plt.show()\n",
    "\n",
    "    vertex_degrees = list(dict(nx.degree(G)).values()) \n",
    "    plt.hist(vertex_degrees, bins = np.linspace(0, 300, 80),\n",
    "            facecolor='blue', alpha=0.75, rwidth = 0.9) \n",
    "    plt.title(\"Vertex degree distribution\") \n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    n = nx.number_of_nodes(G)\n",
    "    m = nx.number_of_edges(G)\n",
    "    cc = nx.average_clustering(G)\n",
    "    triangles = np.trace(np.matrix((nx.to_numpy_matrix(G)**3))/6)\n",
    "    try:\n",
    "        avg_path_length = nx.average_shortest_path_length(G)\n",
    "        diameter = nx.diameter(G)\n",
    "    except: #in case graph is not fully connected\n",
    "        avg_path_length = 'error'\n",
    "        diameter = 'error'\n",
    "    print(\"|V| =\", n)\n",
    "    print(\"|E| =\", m)\n",
    "    print(\"Average degree is\", 2 * m / n) \n",
    "    print(\"CC =\", cc)\n",
    "    print('Number of triangles = ', triangles)\n",
    "    print('Average path length = ', avg_path_length)\n",
    "    print('Diameter = ', diameter)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code For Facebook Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/George/Desktop/anaconda/lib/python3.6/site-packages/networkx/drawing/nx_pylab.py:126: MatplotlibDeprecationWarning: pyplot.hold is deprecated.\n",
      "    Future behavior will be consistent with the long-time default:\n",
      "    plot commands add elements without first clearing the\n",
      "    Axes and/or Figure.\n",
      "  b = plt.ishold()\n"
     ]
    }
   ],
   "source": [
    "'''Retrieving Facebook network data and plotting it'''\n",
    "FbData = np.loadtxt(\"facebook_combined.txt\")\n",
    "FbData = FbData.astype(int)\n",
    "F = nx.Graph()\n",
    "F.add_edges_from(FbData)\n",
    "print_network_data(F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code For In-Built Random Models (ER,WS,BA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Creating and plotting the Erdős-Rényi network'''\n",
    "E = nx.erdos_renyi_graph(4039,0.01081)\n",
    "print_network_data(E)\n",
    "\n",
    "'''Creating and plotting the Watts-Strogatz Network'''\n",
    "W = nx.watts_strogatz_graph(4039, 44, 0.05)\n",
    "print_network_data(W)\n",
    "\n",
    "'''Creating and plotting the Barabási-Albert network'''\n",
    "B = nx.barabasi_albert_graph(4039, 22)\n",
    "print_network_data(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code For MDA Random Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Function for creating a MDA network graph'''\n",
    "def mda(n,m):\n",
    "    A = np.ones((m+1,m+1)) - np.diag(np.ones(m+1))\n",
    "    B = np.zeros((n,n)) \n",
    "    B[0:m+1,0:m+1] = A \n",
    "    for i in range(m+1,n):\n",
    "        mediator=np.random.choice(np.array(list(range(i))))\n",
    "        neighbor = B[mediator,:]\n",
    "        neighbor_index = np.where(neighbor >0)[0]\n",
    "        vec_rand = np.random.choice(np.size(neighbor_index),m,replace = False) \n",
    "        a= neighbor_index[vec_rand[range(m)]]\n",
    "        B[a,i]=1\n",
    "        B[i,a]=1\n",
    "    M = nx.Graph(B)\n",
    "    return M\n",
    "    \n",
    "'''Plotting the Mediation-Driven Attachment Network'''\n",
    "M = mda(4039,22)\n",
    "print_network_data(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code For Clustom Random Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Function that splits the number of nodes, n, into g clusters in the main function'''\n",
    "def splitn(n,g):\n",
    "    listofsubgraphs = [1]*(g+1) \n",
    "    #extra cluster because 0th cluster is too small to be significant\n",
    "    for _ in range(n-g):\n",
    "        listofsubgraphs[int(np.cbrt(np.random.randint((g+1)**(3))))] += 1\n",
    "        #using y=x**3 to form a biased distribution\n",
    "    for i in range(len(listofsubgraphs)-2,-1,-2):\n",
    "        listofsubgraphs += [listofsubgraphs.pop(i)] \n",
    "        #sort to get largest subgraphs to be in the middle\n",
    "    return listofsubgraphs\n",
    "\n",
    "'''Function for creating WS graphs' adjacency matrices in the main function.'''\n",
    "def wsmatrix(n, l, p):\n",
    "    k = int(n*(l**(n//500+1))/2)*2\n",
    "    B = (np.arange(n).reshape(n, 1) - np.arange(n).reshape(1, n)) % n\n",
    "    A = 1 * (((B >= 1) & (B <= k/2)) | ((B >= n - k/2) & (B <= n-1)))\n",
    "    for i in range(n):\n",
    "        v_maybe_rewired = (i + np.arange(1, k //2 +1)) % n\n",
    "        v_rewired = v_maybe_rewired[np.random.rand(k // 2) < p]\n",
    "        v_maybe_rewired_to = np.where((A[i, :] == 0) & (np.arange(n) != i))[0]\n",
    "        v_rewired_to = np.random.choice(v_maybe_rewired_to, len(v_rewired), replace = False)\n",
    "        A[v_rewired, i] = 0\n",
    "        A[i, v_rewired] = 0\n",
    "        A[v_rewired_to, i] = 1\n",
    "        A[i, v_rewired_to] = 1\n",
    "    return A\n",
    "\n",
    "'''Function for creating Clustom network graph'''\n",
    "def customrandomgraph(n, g, l, p, q):\n",
    "    if n < g or p > 1 or q > 1:\n",
    "        return 'error'\n",
    "    else: n = splitn(n,g)\n",
    "    ws = [wsmatrix(i,l,p) for i in n]\n",
    "    listofclusters = [[] for i in range(g+1)]\n",
    "    for h in range((g+1)**2):\n",
    "        i = h//(g+1)\n",
    "        j = h%(g+1)\n",
    "        if j == i:\n",
    "            listofclusters[i] += [ws[i]]\n",
    "        else:   \n",
    "            distance = min(j-i,g-j+i+1)\n",
    "            listofclusters[i] += [1*(np.random.rand(n[i],n[j]) < (q/distance**2))]\n",
    "    A = np.triu(np.concatenate([np.concatenate(m,1) for m in listofclusters]))\n",
    "    custommatrix = np.mat(A + A.T)\n",
    "    return nx.Graph(custommatrix) \n",
    "\n",
    "'''Function for plotting the Clustom network\n",
    "m is the desired number of edges, e is the error range for number of edges\n",
    "Prints progress as it runs'''\n",
    "def plotcrm(n, g, l, p, q, m, e):\n",
    "    difference = e\n",
    "    while difference >= e:\n",
    "        print('Finding graph,')\n",
    "        try:\n",
    "            print('creating adjacency matrix,')\n",
    "            C = customrandomgraph(n, g, l, p, q)\n",
    "            print('checking connectedness,')\n",
    "            d = nx.diameter(C)\n",
    "        except:\n",
    "            print('error.')\n",
    "            continue\n",
    "        else:\n",
    "            difference = abs(nx.number_of_edges(C) - m)\n",
    "            if difference >= e:\n",
    "                print('number of edges not optimal.')\n",
    "    print('graph found, plotting graph.')\n",
    "    print_network_data(C)\n",
    "    return None\n",
    "\n",
    "'''Plotting the Clustom Network'''\n",
    "plotcrm(4039, 7, 0.27, 0.09, 0.0001, 88234, 3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code For SIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Generating network for SIR model'''\n",
    "G = plotcrm(400, 7, 0.27, 0.09, 0.001,0,99999)\n",
    "\n",
    "'''SIR function'''\n",
    "def SIR(A, init, p, q, d):\n",
    "    #A: adjancency matrix\n",
    "    #init: number of infected nodes at day 0\n",
    "    #p: probabilty of infecting those who are Susceptible\n",
    "    #q: probability of recovering from being Infected\n",
    "    #d: number of days\n",
    "    \n",
    "    G = nx.Graph(A)\n",
    "    nx.draw_networkx(G)\n",
    "    plt.show()\n",
    "    n = len(A)\n",
    "    Number_of_susceptible = [n-init]\n",
    "    Number_of_infected = [init]\n",
    "    Number_of_recovered = [0]\n",
    "    print('Day 0')\n",
    "    \n",
    "    #create a list to contain nodes that are infected\n",
    "    #initialise with random nodes that are Infected\n",
    "    IList = np.array(random.sample(range(n),init)) \n",
    "    #create a list to contain nodes that have a chance of being infected\n",
    "    SList = np.setdiff1d(np.arange(n),IList) #contain nodes that has not been Infected\n",
    "    RList = np.array([]).astype(int) #initialise with empty list\n",
    "\n",
    "    print('Number of Infected',init,', Infected List:',IList, '\\n')\n",
    "    \n",
    "    #as the days go by from day 0 to day n+1, the lists will change, \n",
    "    so we use a for loop to iterate each day\n",
    "    for i in range(1,d): \n",
    "        print(\"Day\",i)\n",
    "        #search through the infected list to check if each node has recovered\n",
    "        for node in IList: \n",
    "            if np.random.rand() < q:\n",
    "                RList = np.append(RList,node) #add the recovered nodes to the Recovered List\n",
    "        IList = np.setdiff1d(IList,RList) #remove recovered nodes from the infected list       \n",
    "        \n",
    "        #finding infected neighbours of susceptible nodes\n",
    "        B = np.copy(A)\n",
    "        B[:,SList.astype(int)] = 0  \n",
    "        B[:,RList.astype(int)] = 0\n",
    "        B[IList.astype(int),:] = 0\n",
    "        B[RList.astype(int),:] = 0\n",
    "        #the probability of infection for each susceptible node\n",
    "        is based on the number of infected neighbours\n",
    "        #loop through the susceptible list and append nodes that\n",
    "        have been infected to the infected list\n",
    "        for node in SList:\n",
    "            #the probability of infection for each susceptible \n",
    "            node is based on the number of infected neighbours\n",
    "            Probability_of_infection = 1-(1-p)**(np.sum(B[node]))\n",
    "            if np.random.rand() < Probability_of_infection:\n",
    "                #add the newly infected nodes to the Infected list\n",
    "                IList = np.append(IList,node) \n",
    "        #remove the infected nodes from the Susceptible list\n",
    "        SList = np.setdiff1d(SList,IList) \n",
    "        Number_of_susceptible.append(len(SList))\n",
    "        Number_of_infected.append(len(IList))\n",
    "        Number_of_recovered.append(len(RList))\n",
    "        #print(\"Susceptible:\", len(SList), \", Infected:\", len(IList), \", Recovered List:\", len(RList))\n",
    "        #print()\n",
    "\n",
    "    #plt.plot(np.arange(d), Number_of_susceptible, label = 'Susceptible')\n",
    "    #plt.plot(np.arange(d), Number_of_infected, label = 'Infected')\n",
    "    #plt.plot(np.arange(d), Number_of_recovered, label = 'Recovered')\n",
    "    #plt.legend(loc = 'center right')\n",
    "    #plt.xlabel('Days')\n",
    "    #plt.ylabel('Individuals')\n",
    "    #plt.show()\n",
    "    return Number_of_infected\n",
    "\n",
    "'''Running SIR'''\n",
    "RunSIR = SIR(A, 8, 0.6, 0.6, 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code For PSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Retrieving Google Trend data'''\n",
    "Googletrend_KimTrumpData = np.loadtxt(\"TrumpKim12weeks.txt\")\n",
    "days = list(range(12))\n",
    "google_search = Googletrend_KimTrumpData\n",
    "A = (nx.adjacency_matrix(G).todense())\n",
    "\n",
    "'''Modified SIR function to reduce computation time in PSO function'''\n",
    "def PSO_SIR(A, init, p, q, w):\n",
    "    G = nx.Graph(A)\n",
    "    n = len(A)\n",
    "    infected = [init]\n",
    "    \n",
    "    IList = np.arange(0,n,int(n/init)) #systematic sampling to partially seed results\n",
    "    SList = np.setdiff1d(np.arange(n),IList)\n",
    "    RList = np.array([]).astype(int)\n",
    "    \n",
    "    for i in range(1,w): \n",
    "        for node in IList: \n",
    "            if np.random.rand() < q:\n",
    "                RList = np.append(RList,node)\n",
    "        IList = np.setdiff1d(IList,RList)    \n",
    "        \n",
    "        B = np.copy(A)\n",
    "        B[:,SList.astype(int)] = 0  \n",
    "        B[:,RList.astype(int)] = 0\n",
    "        B[IList.astype(int),:] = 0\n",
    "        B[RList.astype(int),:] = 0\n",
    "        \n",
    "        for node in SList:\n",
    "            Probability_of_infection = 1-(1-p)**(np.sum(B[node]))\n",
    "            if np.random.rand() < Probability_of_infection:\n",
    "                IList = np.append(IList,node) \n",
    "        SList = np.setdiff1d(SList,IList)\n",
    "        infected.append(len(IList))\n",
    "    \n",
    "    maxvalue = max(infected)\n",
    "    normalised_infected = np.array(infected)*(100/maxvalue)\n",
    "    trend = Googletrend_KimTrumpData\n",
    "    difference = np.sqrt(sum(((normalised_infected-trend)/100)**2))\n",
    "    #each value is taken as a percentage to keep difference small\n",
    "    print('p = %f, q = %f, difference = %f'%(p, q, difference))\n",
    "    print(normalised_infected)\n",
    "    return difference\n",
    "\n",
    "'''Function used in the PSO function'''\n",
    "def f(x): #x = [p,q]\n",
    "    p = x[0]\n",
    "    q = x[1]\n",
    "    difference = PSO_SIR(A, 8, p , q, 12)\n",
    "    return difference\n",
    "\n",
    "'''Running PSO'''\n",
    "lb = [0.2, 0.5]\n",
    "ub = [0.4, 0.7]\n",
    "pq_value, distance = pso(f, lb, ub) \n",
    "p = pq_value[0]\n",
    "q = pq_value[1]\n",
    "\n",
    "'''Code for printing the Google Trend and optimized SIR trend'''\n",
    "distance = 1\n",
    "while distance >= 0.6:\n",
    "    plt.title('Google Trend v.s. SIR Trend')\n",
    "    plt.plot(days, google_search, color='g', label = 'Google Trend')\n",
    "    plt.legend(loc = 'center right')\n",
    "    distance = PSO_SIR(A, 8, p, q, 12)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
